{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "leading-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json\n",
    "import random\n",
    "import re\n",
    "import pronouncing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This just makes a list of all lines of poetry, sans extra whitespace\n",
    "all_lines =[]\n",
    "for line in gzip.open(\"gutenberg-poetry-v001.ndjson.gz\"):\n",
    "    all_lines.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mental-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds a dictionary that maps words with that rhyming part to the lines of poetry that they're found at the end of.\n",
    "from collections import defaultdict\n",
    "\n",
    "by_rhyming_part = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for line in all_lines:\n",
    "    text = line['s']\n",
    "    if not(32 < len(text) < 48): # only use lines of uniform lengths\n",
    "        continue\n",
    "        # /b indicates word boundaries\n",
    "        # w+ 'word character' alphanumeric I think\n",
    "        # W not word character \n",
    "        \n",
    "    match = re.search(r'(\\b\\w+\\b)\\W*$', text)\n",
    "    \n",
    "    if match:\n",
    "        last_word = match.group()\n",
    "        pronunciations = pronouncing.phones_for_word(last_word)\n",
    "        if len(pronunciations) > 0:\n",
    "               rhyming_part = pronouncing.rhyming_part(pronunciations[0])\n",
    "               # group by rhyming phones (for rhymes) and words (to avoid duplicate words)\n",
    "               by_rhyming_part[rhyming_part][last_word.lower()].append(text)\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "standing-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_frame = pd.DataFrame(by_rhyming_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "inside-swift",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "justlines = []\n",
    "for each in all_lines:\n",
    "    justlines.append(each['s'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "solid-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "no_punct = []\n",
    "for each in justlines:\n",
    "    punctless = each.strip(string.punctuation)\n",
    "    no_punct.append(punctless)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-feeding",
   "metadata": {},
   "source": [
    "### Certain words aren't being caught by my pronunciation checker. Is it 'cause they're old english or something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "english-heading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#source_word = 'knelling'\n",
    "#print(source_word.isalpha())\n",
    "#phones = pronouncing.phones_for_word(source_word)[0] #\n",
    "#print(phones)\n",
    "#rhyming_part = pronouncing.rhyming_part(phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-coordination",
   "metadata": {},
   "source": [
    "These words make my prounouncing library dry heave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "systematic-pilot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347149"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words =[]\n",
    "for line in no_punct:\n",
    "    text = line\n",
    "    source_word = text.split(' ')[-1]\n",
    "    try:\n",
    "        pronouncing.phones_for_word(source_word)[0]\n",
    "    except IndexError:\n",
    "        bad_words.append(text.split(' ')[-1])\n",
    "len(bad_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "approximate-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321563      scornfully\n",
       "32336       Eden-glade\n",
       "237206            wo√æe\n",
       "127901         \"Father\n",
       "39112     bridle-reins\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = pd.Series(bad_words)\n",
    "bad_words.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intense-superior",
   "metadata": {},
   "source": [
    "That's a huge number of bad words. A lot of them have punctuation at the end. I suspect a lot of those are salvagable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-services",
   "metadata": {},
   "source": [
    "## Analysis of original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "front-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This doesn't work. But it feels like it should.\n",
    "def sentimenter(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    subjectivity = sentiment.subjectivity\n",
    "    return (subjectivity)\n",
    "def polarityer(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    polarity = sentiment.polarity\n",
    "    return (polarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ongoing-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct_no_repeats = set(no_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "swedish-belgium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From every eye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Of the freaked flag and meadow buttercup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So thickly studded, in the depth of Mars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fight and fight on, exulting in the light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Within the dripping churchyard, the rain plash...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line\n",
       "0                                     From every eye\n",
       "1           Of the freaked flag and meadow buttercup\n",
       "2           So thickly studded, in the depth of Mars\n",
       "3          Fight and fight on, exulting in the light\n",
       "4  Within the dripping churchyard, the rain plash..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame(no_punct_no_repeats)\n",
    "corpus['Line'] = corpus[0]\n",
    "corpus.drop([0], axis=1, inplace= True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-settle",
   "metadata": {},
   "source": [
    "corpus['sentiment'] = corpus['Line'].apply(sentimenter)\n",
    "print('THE CODE IS RUNNING, I SWEAR.')\n",
    "corpus['polarity'] = corpus['Line'].apply(polarityer)\n",
    "corpus.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "jewish-removal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "central-roller",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4cf2e958e86d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcount_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngram_range\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcount_matrix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcount_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Line'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1200\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1202\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1203\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mngrams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mngrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# handle stop words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# handle token n-grams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    224\u001b[0m         \u001b[1;31m# handle stop words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m             \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m         \u001b[1;31m# handle token n-grams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "count_matrix = count_vect.fit_transform(corpus['Line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "latin-material",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2665604, 4551288)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "solved-yield",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 391. GiB for an array with shape (52451621499,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-6c6ac048d4b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_kernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcos_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[0mY_normalized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m     K = safe_sparse_dot(X_normalized, Y_normalized.T,\n\u001b[0m\u001b[0;32m   1189\u001b[0m                         dense_output=dense_output)\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    558\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    559\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rmatmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    478\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m         \u001b[1;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\prathmun\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    516\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmajor_axis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 518\u001b[1;33m         \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    519\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 391. GiB for an array with shape (52451621499,) and data type int64"
     ]
    }
   ],
   "source": [
    "\n",
    "cos_sim = cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-sunrise",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sorted-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_assign = corpus.reset_index() \n",
    "def watchme(movie):\n",
    "    movie_idx = idx_assign[idx_assign['Line'] == movie].index[0]\n",
    "    sim_array = cos_sim[movie_idx]\n",
    "    array_lst = list(enumerate(sim_array))\n",
    "    sort_lst = sorted(array_lst, reverse=True, key = lambda x: x[1])\n",
    "    top_recs = sort_lst[0:40]\n",
    "    for i in top_recs:\n",
    "        print(idx_assign.loc[i[0]].Line)\n",
    "    return top_recs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-sullivan",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "watchme(corpus['Line'].loc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-armor",
   "metadata": {},
   "source": [
    "###  The below does not include cosin similarity\n",
    "\n",
    "This could be resolved by producing a list of similar lines, as above, and then selecting randomly, or the first that rhymes from it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-confidentiality",
   "metadata": {},
   "source": [
    "# THE MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bottom-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This whole thing doesn't work super reliably. Some of it has to do with the pronunciation library missing words in my corpus,\n",
    "#some of it has to do with punctuation. Working on it, but it's not super high priority.\n",
    "def limirick_machine(tone_param=True):\n",
    "    #tone_param, sorts sentiment. True = ascending, or sad, false = Descending, or happy\n",
    "    #Finds you lines that don't need to rhyme\n",
    "    def initial_line_finder(list_of_existing):\n",
    "        rand_choice = random.choice(no_punct)\n",
    "        if rand_choice not in list_of_existing:\n",
    "            line = rand_choice\n",
    "            \n",
    "        while line.split(' ')[-1].isalpha() == False:\n",
    "            rand_choice = random.choice(no_punct)\n",
    "            if rand_choice not in list_of_existing:\n",
    "                line = rand_choice\n",
    "        \n",
    "        flag = False\n",
    "        while flag == False:            \n",
    "            try:\n",
    "                \n",
    "                word_to_rhyme = line.split(' ')[-1]\n",
    "                phones = pronouncing.phones_for_word(word_to_rhyme)\n",
    "                phones = phones[0]\n",
    "                flag= True\n",
    "                \n",
    "            except IndexError:  \n",
    "                \n",
    "                rand_choice = random.choice(no_punct)\n",
    "                while line.split(' ')[-1].isalpha() == False:\n",
    "                    rand_choice = random.choice(no_punct)\n",
    "                    if rand_choice not in list_of_existing:\n",
    "                        line = rand_choice\n",
    "                phones = pronouncing.phones_for_word(word_to_rhyme)\n",
    "                phones = phones[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        ###\n",
    "        \n",
    "        rhyming_phones = pronouncing.rhyming_part(phones)\n",
    "        return line, rhyming_phones\n",
    "    \n",
    "    # Finds lines that end with similar rhymes.\n",
    "    def secondary_line_finder(list_of_existing, phones_to_rhyme, cosine_buddy):   \n",
    "        \n",
    "        \n",
    "        rand_choice = ''\n",
    "        ##############################################\n",
    "        \n",
    "        def rhymeme(movie, tone=True):\n",
    "            def sentimenter(line):\n",
    "                sentiment= TextBlob(line).sentiment\n",
    "                subjectivity = sentiment.subjectivity\n",
    "                return (subjectivity)\n",
    "                \n",
    "            movie_idx = idx_assign[idx_assign == movie].index[0]\n",
    "            idx_assign['line'] = idx_assign[0]\n",
    "            idx_assign.drop(inplace=True, axis=1, labels=[0])\n",
    "            sim_array = cos_sim[movie_idx]\n",
    "            \n",
    "            \n",
    "            array_lst = list(enumerate(sim_array))\n",
    "            \n",
    "\n",
    "            sort_lst = sorted(array_lst, reverse=True, key = lambda x: x[1])\n",
    "            cosign_df = pd.DataFrame(sort_lst)\n",
    "            cosign_df['orig_ind'] = cosign_df[0] \n",
    "            \n",
    "            cosign_df.drop(inplace=True, axis=1, labels=[0])\n",
    "            cosign_df['cosign_score'] = cosign_df[1]\n",
    "            cosign_df.drop(inplace=True, axis=1, labels=[1])\n",
    "            #builds a df with both cosign similarity and sentiment in it\n",
    "            co_sentiment_df = idx_assign.merge(cosign_df, left_on='index', right_on='orig_ind')\n",
    "            co_sentiment_df['sentiment'] = co_sentiment_df['line'].apply(sentimenter)\n",
    "            co_sentiment_df.sort_values(['cosign_score'], ascending=False)\n",
    "            co_sentiment_df.drop(inplace=True, axis=1, labels=['index', 'orig_ind'])\n",
    "            #Sorts by cosign\n",
    "            sorted_cosign = co_sentiment_df.sort_values(['cosign_score'], ascending=False).head(10)\n",
    "            #Sorts the dataframe by sentiment\n",
    "            sorted_sentiment = sorted_cosign.sort_values(['sentiment'], ascending=False)\n",
    "            sorted_sentiment.drop(axis=0, labels=[0], inplace=tone)\n",
    "\n",
    "            final_phrase = sorted_sentiment['line'].iloc[0]\n",
    "\n",
    "            return final_phrase\n",
    "        ##############################################\n",
    "        \n",
    "        while rand_choice in list_of_existing or rand_choice =='':\n",
    "            key = random.choice(list(by_rhyming_part[phones_to_rhyme].keys()))    \n",
    "            list_of_rhyming_lines = list(by_rhyming_part[phones_to_rhyme][key])\n",
    "\n",
    "            count_vect = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "            to_vectorize = list_of_rhyming_lines\n",
    "            to_vectorize.append(cosine_buddy)\n",
    "            \n",
    "            \n",
    "            count_matrix = count_vect.fit_transform(to_vectorize)\n",
    "            cos_sim = cosine_similarity(count_matrix)\n",
    "            \n",
    "            rhyming_series = pd.Series(to_vectorize)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            idx_assign = rhyming_series.reset_index() \n",
    "            rand_choice = rhymeme(cosine_buddy, tone_param)\n",
    "            \n",
    "            \n",
    "        return rand_choice\n",
    "            \n",
    "\n",
    "    list_of_lines = []\n",
    "    line1, line1_phones = initial_line_finder(list_of_lines)\n",
    "    list_of_lines.append(line1)\n",
    "        \n",
    "    line2 = secondary_line_finder(list_of_lines, line1_phones, list_of_lines[-1])\n",
    "    list_of_lines.append(line2)\n",
    "    \n",
    "    line3, line3_phones = initial_line_finder(list_of_lines)\n",
    "    list_of_lines.append(line3)\n",
    "    \n",
    "    line4 = secondary_line_finder(list_of_lines, line3_phones,list_of_lines[-1])\n",
    "    list_of_lines.append(line4)\n",
    "    \n",
    "    line5 = secondary_line_finder(list_of_lines, line1_phones,list_of_lines[-1])\n",
    "    \n",
    "\n",
    "    return line1, line2, line3, line4, line5\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "sapphire-audit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "  \n",
      "Some indiscreet Abderite boys\n",
      "\"How beautiful the sea! How she enjoys\n",
      "The lawes of his lond to holde\n",
      "The sweeping storm, mighty, like flag unrolled\n",
      "Of dalliance had with thee in Heav'n, and joys\n"
     ]
    }
   ],
   "source": [
    "line1, line2, line3, line4, line5 = limirick_machine(tone_param=True)\n",
    "print('  ')\n",
    "print('  ')\n",
    "print(line1)\n",
    "print(line2)\n",
    "print(line3)\n",
    "print(line4)\n",
    "print(line5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faced-warrant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Manhood to God-head, with more strength to foil', 'Manhood to Godhead, with more strength to foil', 'Up then and with thy courage put to foil', 'Of Moultrie and of Eutaw--who shall foil', 'THAT shall for ever live and foil', \"Of proofs new-bleeding, which remain'd the foil\", 'Manhood to God-head, with more strength to foil', 'For vacant glitter.  It were scarce a foil', \"And what's more wonderful, when big loads foil\", \"By no man's arrow reach'd; I fear no foil\", 'Hither most gentle sleep! and soothing foil', 'Nor mendicant nor ballad beggar foil', 'Scorning, and bent, with feet of wind, to foil', 'With what gay spirit does she foil', 'Songs of their brother-hours shall foil', 'Or the dull lisp of oaken limbs that foil', 'And even superstition, fails to foil', 'Of Moultrie and of Eutaw--who shall foil', 'I do confess the fairness of the spoil']\n",
      "['But the great loss should by instinct impair', \"Learn his departure, lest thou should'st impair\", 'Ulysses, ruthless Chief! no toils impair', 'Or, it may be, with Demons, who impair', 'With unseen fingers long and soft! and there']\n",
      "['_From a drawing by_ RICHARD DOYLE', 'Or, it may be, with Demons, who impair']\n",
      "['Manhood to God-head, with more strength to foil', 'Manhood to Godhead, with more strength to foil', 'Up then and with thy courage put to foil', 'Of Moultrie and of Eutaw--who shall foil', 'THAT shall for ever live and foil', \"Of proofs new-bleeding, which remain'd the foil\", 'Manhood to God-head, with more strength to foil', 'For vacant glitter.  It were scarce a foil', \"And what's more wonderful, when big loads foil\", \"By no man's arrow reach'd; I fear no foil\", 'Hither most gentle sleep! and soothing foil', 'Nor mendicant nor ballad beggar foil', 'Scorning, and bent, with feet of wind, to foil', 'With what gay spirit does she foil', 'Songs of their brother-hours shall foil', 'Or the dull lisp of oaken limbs that foil', 'And even superstition, fails to foil', 'Of Moultrie and of Eutaw--who shall foil', 'Or, it may be, with Demons, who impair']\n",
      "['_From a drawing by_ RICHARD DOYLE', 'Or, it may be, with Demons, who impair']\n",
      "[\"'When tyrants scourge, or demagogues embroil\", 'When tyrants scourge, or demagogues embroil', 'Or, it may be, with Demons, who impair']\n",
      "['Poppies of Lethe, and let slay a sheep', 'On nights like this the huddled sheep', 'And pluck the wool from stinking sheep', 'A hard division, when the harmless sheep', 'They sighing left the lands, his silver sheep', 'Thither no groom drives forth his tender sheep', \"The herd that on the hills o' sheep\", 'She folds her tawny heifers and her sheep', 'When I was young and herdit sheep', 'Upon the half-thawed snow the bleating sheep', 'Upon the half-thawed snow the bleating sheep', 'Among the mullein stalks the sheep', 'Better than cattle and better than sheep', 'And onward with his travelling sheep', 'Yet the stern shepherds of the poor black sheep', 'And oxen from the city, and goodly sheep', 'I am not sent but unto the lost sheep', 'And drive this motley flock of sheep', 'Halloo, halloo to the lily-white sheep', 'On the solitary pastures where our sheep', 'And then a wise bell-wether sheep', 'And one is of an old half-witted sheep', 'Heifers and goats and kids, and foolish sheep', 'Right to the bridge, where all our sheep', 'Roasting a thick-woolled mountain sheep', 'And why that sadness? when I passed our sheep', 'And yet these wilful wandering sheep', 'Whose joy is, to the wandering sheep', 'And high amongst the glimmering sheep', 'That shepherded the moonlit sheep', 'May weigh with life; of oxen and of sheep', \"Came on the gen'ral crowd; as flocks of sheep\", 'Then waves like flocks of silver sheep', 'Of orphan \"Lubin,\" who, while tending sheep', '\"Suppose there were near by a flock of sheep', 'Of that loved village where he left his sheep', 'And in one night send twenty score of sheep', \"Upon the child, if he dislurb'd the sheep\", 'When first I went a-washing sheep', 'That Shepherd keen seeks one lost sheep', 'On the solitary pastures where our sheep', 'Drive hither from the city fatted sheep', 'As if he find a flock unguarded, sheep', \"Spacious, and sprinkled o'er with silver sheep\", 'Thou hast much gold, much brass, and many sheep', 'To and fro, occupied around a sheep', '\"Little Bo-Peep she lost her sheep', 'Perhaps their loves, or else their sheep', 'Like us have gone; the silly sheep', 'Led out their kine to pasture. Goats and sheep', 'And give to me four score of Yorkshire sheep', \"Com'st thou, whom never, heretofore, my sheep\", \"Then disembark'd, and of the Cyclops' sheep\", \"Or num'rous flock, none here shall either sheep\", 'And from the pastures on all sides the sheep', 'To be spectators daily of our sheep', 'Little Bo-peep has lost her sheep', \"‚ÄúLet from dread Boreas' piercing cold the sheep\", 'Untended still, her silly, vagrant sheep', 'And when the clouds like folded sheep', 'Gathered together like a flock of sheep', \"The herd that on the hills o' sheep\", 'O my poor darling, O my little lost sheep', 'On the solitary pastures where our sheep', 'Perhaps their loves, or else their sheep', 'These led the horses, and, as marshalled sheep', 'And then we lie and count up sheep', 'While the shepherd sets wolves on his sheep', 'And say to God: Behind these are the sheep', 'A pair of lapwings, one old sheep', 'A shepherd rose to call his sheep', 'For love of her, each mother-sheep', 'I lay a-musing,--while the silly sheep', 'The huddling trample of a drove of sheep', '\"And a hundred calves and a hundred sheep', '\"Stand thou and see us shear thy sheep', 'Upon the child, if he disturbed the sheep', 'The little white clouds are like sheep', 'Or the keen cunning of the crafty Sheep', \"They lull'd Kilmeny sound asleep\"]\n",
      "[\"Th' unfounded deep, & through the void immense\", 'This life of mine, for favours so immense', '\"\\'Twere hard,\" it answered, \"themes immense', 'Have sought thy volume, and with love immense', 'Have sought thy volume, and with love immense', 'Amidst the soundless solitudes immense', \"Th' unfounded deep, & through the void immense\", 'Sucks down its prey insatiable.  Immense', \"No mere mote's-breadth but teems immense\", 'If you wish to know the power immense', 'We, the Company--still more to show how immense', 'Have sought thy volume, and with love immense', 'Have sought thy volume, and with love immense', 'Have sought thy volume, and with love immense', 'Of white-robed Scholars only) this immense', 'I deem. What wealth, how various, how immense', 'To the tenth generation, so immense', 'To the tenth generation; so immense', \"Beneath the smoking sirloin, stretch'd immense\", 'The walls of infant Troy; with toil immense', 'Leapt like a hunted stag through one immense', 'Suggest the tritons. Through the blue Immense', 'Of white-robed Scholars only) this immense', 'This life of mine, for favors so immense', 'I share with thee the hermitage immense', 'Of systems yet unshaped, that hang immense', 'Clouds roll before a blue immense', 'And although our love has become an immense', 'seeking it nowhere else than in your immense', 'O Sun, who bring forth and deliver, O immense', 'Upon these earthly shores, and hence']\n",
      "['And on the ground the miserable Bopeep', \"Th' unfounded deep, & through the void immense\"]\n",
      "['Both day and night: how often from the steep', 'Both day and night:  How often from the steep', 'Sore watched and weary, he began to steep', 'The passage hard against the mountain steep', 'The camp was won, and all in blood doth steep', 'For neither were ye playing on the steep', 'An unmixed void in things, they fear the steep', \"With hue ferruginous, e'en as the steep\", 'Him back returning, who behind the steep', 'Where teems so plenteously the Alpine steep', '\"Here enter on a ladder far less steep', \"With hue ferruginous, e'en as the steep\", 'Him back returning, who behind the steep', 'Where teems so plenteously the Alpine steep', '\"Here enter on a ladder far less steep', 'And his love-kindling fire did quickly steep', \"O'er billowy plain and mountain steep\", 'In the black shade of what obsidian steep', \"Though from this castle's walls so steep\", 'Never did sun more beautifully steep', 'And farther up the heavenly steep', 'Both day and night: how often from the steep', 'I took compassion on her, bade her steep', 'If we could see the morrow from the steep', 'O that the pines which crown yon steep', \"Mixed in her drink three drops, 'twill steep\", 'Woke from its trance-like lethargy, to steep', 'In common things, as, not to steep', \"Flowers of night's grafting, strong to steep\", 'Yon strange blue city crowns a scarped steep', 'As skilful divers from some airy steep', 'But how, unbidden, shall I dare to steep', '\"Permit me now, beloved of Jove! to steep', 'Aurora now was rising up the steep', 'That chafe the wild and stormy steep', 'Its venomous tear and nightly steep', \"No, ne'er did the wave in its element steep\", 'Of the dread height to which that steep', '\"And sunk myself as low as hell can steep', '\"This very night his blood shall steep', 'And long is heard from steep to steep', 'To their young loves, reclined the steep', \"With hue ferruginous, e'en as the steep\", \"With hue ferruginous, e'en as the steep\", \"With hue ferruginous, e'en as the steep\", 'Him back returning, who behind the steep', 'Where teems so plenteously the Alpine steep', '\"Here enter on a ladder far less steep', 'Him back returning, who behind the steep', 'Where teems so plenteously the Alpine steep', '\"Here enter on a ladder far less steep', 'Him back returning, who behind the steep', 'Where teems so plenteously the Alpine steep', '\"Here enter on a ladder far less steep', \"With hue ferruginous, e'en as the steep\", 'To this place from the stone upon the steep', 'While we must keep to the foot-path steep', \"You'll never mount the airy steep\", 'Fast by the fords of Alpheus, and from steep', 'Of brain-disturbing Bacchus down the steep', 'Arising sudden, down the rugged steep', 'Though avalanches roared from steep to steep', 'Nor pealed not surely back from deep to steep', 'Sound like a stream at nightfall from the steep', 'Dulichium, Same and the rock-bound steep', \"With awful ravage, AEtna's neighbouring steep\", 'Unmoved he stands, as when a rocky steep', 'For neither were ye playing on the steep', 'Never did sun more beautifully steep', \"Fell'd a tree, while on the steep\", 'Itself to apathy, for we must steep', 'For forty miles the way ran steep', 'Men looking down from some sheer dizzy steep', 'He wandered through a valley steep', 'I took compassion on her, bade her steep', 'Amid the gloomy flood, a smooth rock, steep', 'That there is no old power left to steep', \"Foremost of all on battle's fiery steep\", 'Bright glancing down, I rested oft, where steep', 'Fell, as they journeyed. And the furthest steep', 'Till, with glad deer, each flooded steep', '‚ÄôTis hard to climb that towering steep', 'Visit each isle and mountain steep', 'The light that flashes from that steep', 'A hundred leagues from steep to steep', 'He scaled Arish·π≠a‚Äôs glorious steep', 'Planted by Gods each glittering steep', 'Woke from its trance-like lethargy, to steep', 'Who knows but thou hast won the steep', \"There, where Gibraltar's cannon'd steep\", 'The iron twilight closes, and the steep', 'Both day and night. How often from the steep', \"The goddess order'd. Hid beneath a steep\", \"And from the green world's farthest steep\", 'And rugged cliff and barren steep', 'Concord, whose myrtle wand can steep', 'The nice morn, on the Indian steep', 'From a high, mist-engirdled steep', 'Mysterious essences whose wavings steep', 'Never did sun more beautifully steep', 'For neither were ye playing on the steep', 'Its barren brow--barren, but on its steep', 'There stands a rock, from whose impending steep', 'Concord, whose myrtle wand can steep', 'His temples bound with poppy, to the steep', 'For neither were ye playing on the steep', 'Never did sun more beautifully steep', \"Fell'd a tree, while on the steep\", 'Dear Bosom-child we call thee, that dost steep', 'Above, resounds the crash, and down the steep', 'Of pathless woods; or down the craggy steep', 'Slipping down the banks too steep', 'Green visioned banks that are too steep', 'Distending foams tempestuous up each steep', 'With faithful hands still yearning up the steep', 'Or, when the twilight shadows steep', 'And the fair moon, and all the stars that steep', \"Corycia's caverns and the Delphic steep\", 'Are they the Oreads from the Delphian steep', 'Reels all the isle; and every ragged steep', \"Fleet other spectres--from the ruin'd steep\", 'So bright the angel-crowded steep', 'Trembled before it. From the haggard steep', \"The wanderer adown Heaven's azure steep\", \"Of Nature's calm. And yonder on the steep\", \"Till climb'd one evening on a rocky steep\", 'And bare, above, the heathery steep', 'How small he seems, beneath the steep', 'Men looking down from some sheer dizzy steep', 'And then before the sun began his journey steep', 'A horrible thunderous noise, as down the steep', 'To force strong souls along the giddy steep', 'To the old task, and up the rugged steep', 'And bore him toward a dim and perilous steep', '\"To plunge me headlong from that giddy steep', \"I'll go!--and from the high Leucadian steep\", 'Or letters old, I magically steep', 'To human Science, up the toilsome steep', 'And all was hushed above that steep', 'Drew long stork legs, long legs that steep', 'He helped them up the thorny steep', '_The Naiads._ Come, ye sorrowful, and steep', 'Lifting smooth and warm and steep', 'The Dogs are fleet, the way is steep', 'Eternal rocks, from whose prodigious steep', 'We at the margin of a lofty steep', 'The caldrons and with forks the pieces steep', 'Down with this living man from steep to steep', 'And down the darkling plunging steep', \"Th' unfounded deep, & through the void immense\"]\n",
      "['O to dream, O to awake and wander', 'O to dream, O to awake and wander', 'Subject to law? and when thou seemest to wander', 'To punish thee the longer.  Thou shalt wander', 'Here I dwelt, and learnt to wander', 'They ask me, do those others, why I wander', 'O to dream, O to awake and wander', 'Should, perchance, the moose-deer wander', 'That they may not want, nor wander', 'That the great and small may wander', 'Should, perchance, the moose-deer wander', 'That they may not want, nor wander', 'That the great and small may wander', 'In prayer together the way we wander', 'For conscience will not suffer me to wander', 'Venture thou to dream, then, and to wander', 'And with considerate swiftness wander', \"The sweets o' the simmer invite us to wander\", 'Wherfore that gose that styll about wyll wander', 'Before the auters he to and fro doth wander', 'Oh! that I were a fairy sprite, to wander', 'They were the days when all who care to wander', 'Not with joyful thoughts I wander', \"For 'tis always so easy to wander\", 'Where the deer were wont to wander', 'I wonder if ye see me as I wander', 'Home no more home to me, whither must I wander', 'O to dream, O to awake and wander', 'Soon our feet would cease to wander', 'If mountains rose on wings to wander', \"And no mother's child shall wander\", \"Thus 'neath moon and sun to wander\", 'The songs of dead seasons, that wander', 'Attacked the deputy, began to wander', \"Till by himsel' he learned to wander\", \"God's mean and careless servant--while I wander\", 'And here in the night would I wander', 'Wandering they take as they wander', 'And bid him shelter all that starve or wander', 'Whom to seek through all the world I wander', '\"I fear the time has come for me to wander', 'What forth it draws must the one way wander']\n",
      "['Of wy∆ö∆ö and dede ylaced in a cheyne', 'Whom I haue bound so low vnder your cheyne', 'But now of newe, witƒßin hur firy cheyne', 'Me thought I saw witƒß a goldyn cheyne', 'What hopes, what methods of retreat remain']\n",
      "[\"Half the riddle's read, we ponder\", 'I wander, seek and peer and ponder', 'Is but a grey and silent world, but ponder', 'Or sit foredone and desolately ponder', \"O sweet to stray, an' pensive ponder\", 'Some shall pause awhile and ponder', 'And rise not--no more need he suffer or ponder', 'Still, I suppose, they sit and ponder', 'And if for a moment, forgetting to ponder', \"I'll hear no more: 'tis vain to ponder\", \"O sweet, to stray an' pensive ponder\", \"Endymion sat down, and 'gan to ponder\", \"England, by God's grace set apart to ponder\", 'Stole he! Ah, did the oak-wood ponder', 'Now backward I must set my sail, and ponder', 'As in pity I gaze on its branches, and ponder', 'But on that greater ball no heart will ponder', 'Whom I haue bound so low vnder your cheyne']\n",
      "['Yes, thou shalt smile again!--Time always heals', 'To express, in indifferent French, all he feels']\n",
      "[\"Us'd to the yoak, draw'st his triumphant wheels\", \"Us'd to the yoke, drawest his triumphant wheels\", 'Of planets, and of fixed, in all her wheels', 'Horrible discord, and the madding wheels', 'Ascend my chariot, guide the rapid wheels', 'Gloomy as night; under his burning wheels', 'Distinct with eyes, and from the living wheels', 'And the great Thisbite, who on fiery wheels', \"His charioteer, intrench'd betwixt the wheels\", 'By sorrow, and the ministering wheels', 'Who after virtue‚Äôs golden chariot-wheels', 'Meanwhile a giant mound, on star-shaped wheels', 'And Jove while urging the revolving wheels', 'Contend with flying feet or hurrying wheels', 'With eyes upon the everlasting wheels', 'Lift up then, Reader, to the lofty wheels', 'With eyes upon the everlasting wheels', 'Lift up then, Reader, to the lofty wheels', 'Save the fell beast.  He slowly sailing, wheels', \"Had slop'd his beam.  Attendant at the wheels\", 'Yet holds him from observance; for these wheels', 'Save the fell beast.  He slowly sailing, wheels', \"Had slop'd his beam.  Attendant at the wheels\", 'Yet holds him from observance; for these wheels', \"Ye duck and drake, wi' airy wheels\", 'With whistling engines and crunching wheels', 'Resounded to the rattle of the wheels', 'A splash of hoofs and rush of wheels', \"Been stealing fire from Helios' chariot-wheels\", \"As are the tracks of Pharaoh's chariot-wheels\", \"Us'd to the yoak, draw'st his triumphant wheels\", 'Along the coast-way grind the wheels', 'And bids Aurora with her golden wheels', \"O Buonarruoti,--good at Art's fire-wheels\", 'Some raise the painted pavement, some on wheels', 'When they heard out of the silence of wheels', 'It hideth the harsh furrows that the wheels', 'It hideth the harsh furrows that the wheels', 'Save the fell beast.  He slowly sailing, wheels', 'Save the fell beast.  He slowly sailing, wheels', \"Had slop'd his beam.  Attendant at the wheels\", \"Had slop'd his beam.  Attendant at the wheels\", 'Yet holds him from observance; for these wheels', 'Yet holds him from observance; for these wheels', 'Yet holds him from observance; for these wheels', \"Had slop'd his beam.  Attendant at the wheels\", 'Save the fell beast.  He slowly sailing, wheels', 'We lay, nor heard the limber wheels', \"Excited, o'er the charioteers their wheels\", 'So, through the concourse on his rolling wheels', \"Cover'd Iphition, and Achaian wheels\", 'In cruel triumph at his chariot-wheels', 'LXXXIX. Chased by Orsilochus, afar she wheels', \"Ye duck and drake, wi' airy wheels\", 'The foolish flower that turns whereso he wheels', 'That life has circled with returning wheels', \"Follow'd his step; where'er he wheels\", 'Of planets and of fixed in all her wheels', 'The pole of gold; by gold the rolling wheels', 'within the thud-thud of the wheels', 'Sometimes a god will drive his chariot wheels', \"Who after virtue's golden chariot-wheels\", 'The groaning of the old great wheels', 'That to me in my chariot of two wheels', 'Hid in the ocean-waste? Thy chariot wheels', 'One sings to the clatter of wheels', 'shrill with the clanging of ironbound wheels', 'The purr of pinions in the thousand wheels', 'And pace the woods, and drive my chariot wheels', 'And then I see queer dancing wheels', 'The sound of their chariot wheels', 'The Monarch heard the chariot wheels', 'Whose Car of Kultur crushed beneath its wheels', 'To express, in indifferent French, all he feels']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-6a5b19d246b0>\u001b[0m in \u001b[0;36minitial_line_finder\u001b[1;34m(list_of_existing)\u001b[0m\n\u001b[0;32m     20\u001b[0m                 \u001b[0mphones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpronouncing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphones_for_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_to_rhyme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                 \u001b[0mphones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m                 \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-c7a830e07e6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtemp_limirick_dict\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'line1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'line2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'line3'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'line4'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'line5'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mline1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimirick_machine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mtemp_limirick_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtemp_limirick_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'line2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-6a5b19d246b0>\u001b[0m in \u001b[0;36mlimirick_machine\u001b[1;34m()\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[0mlist_of_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m     \u001b[0mline3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mline3_phones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minitial_line_finder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_of_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[0mlist_of_lines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-50-6a5b19d246b0>\u001b[0m in \u001b[0;36minitial_line_finder\u001b[1;34m(list_of_existing)\u001b[0m\n\u001b[0;32m     30\u001b[0m                         \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrand_choice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mphones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpronouncing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mphones_for_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_to_rhyme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                 \u001b[0mphones\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mphones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#initial set up.\n",
    "import pandas as pd\n",
    "temp_limirick_dict= {'line1':[],'line2':[],'line3':[],'line4':[],'line5':[],}\n",
    "for i in range(10):\n",
    "    line1, line2, line3, line4, line5 = limirick_machine()\n",
    "    temp_limirick_dict['line1'].append(line1)\n",
    "    temp_limirick_dict['line2'].append(line2)\n",
    "    temp_limirick_dict['line3'].append(line3)\n",
    "    temp_limirick_dict['line4'].append(line4)\n",
    "    temp_limirick_dict['line5'].append(line5)\n",
    "basic_limirick_df = pd.DataFrame(temp_limirick_dict)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase size\n",
    "#I just run this a few times, errors don't hurt if you just run it again.\n",
    "temp_limirick_dict= {'line1':[],'line2':[],'line3':[],'line4':[],'line5':[],}\n",
    "for i in range(10):\n",
    "    line1, line2, line3, line4, line5 = limirick_machine()\n",
    "    temp_limirick_dict['line1'].append(line1)\n",
    "    temp_limirick_dict['line2'].append(line2)\n",
    "    temp_limirick_dict['line3'].append(line3)\n",
    "    temp_limirick_dict['line4'].append(line4)\n",
    "    temp_limirick_dict['line5'].append(line5)\n",
    "temp_limirick_df = pd.DataFrame(temp_limirick_dict)\n",
    "basic_limirick_df = pd.concat([basic_limirick_df, temp_limirick_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(basic_limirick_df.shape)\n",
    "print(basic_limirick_df.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-burst",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_value = basic_limirick_df['line1'].iloc[0]\n",
    "test_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-blackberry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### This doesn't work. But it feels like it should.\n",
    "def sentimenter(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    subjectivity = sentiment.subjectivity\n",
    "    return (subjectivity)\n",
    "def polarityer(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    polarity = sentiment.polarity\n",
    "    return (polarity)\n",
    "\n",
    "for column in basic_limirick_df:\n",
    "    basic_limirick_df[column + '_sentiment'] = basic_limirick_df[column].apply(sentimenter)\n",
    "    basic_limirick_df[column + '_polarity'] = basic_limirick_df[column].apply(polarityer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-locator",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimenter1('half lying on the grass, yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_limirick_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-palace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "basic_limirick_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "line1_negative_polarity_mask = basic_limirick_df.line1_polarity <0\n",
    "line2_negative_polarity_mask = basic_limirick_df.line2_polarity <0\n",
    "line3_negative_polarity_mask = basic_limirick_df.line3_polarity <0\n",
    "line4_negative_polarity_mask = basic_limirick_df.line4_polarity <0\n",
    "line5_negative_polarity_mask = basic_limirick_df.line5_polarity <0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-heart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gotta reset the index when I concatonate or something. But I'm just annotating on this pass.\n",
    "\n",
    "basic_limirick_df[line1_point2_polarity_mask].head()\n",
    "print(basic_limirick_df['line1'][line1_negative_polarity_mask][5])\n",
    "print(basic_limirick_df['line2'][5])\n",
    "#print(basic_limirick_df['line3'][5])\n",
    "#print(basic_limirick_df['line4'][5])\n",
    "#print(basic_limirick_df['line5'][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a wordcloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"br\", \"href\"])\n",
    "textt = \" \".join(review for review in basic_limirick_df.line2)\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(textt)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud11.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-white",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-designation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-driver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-album",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-return",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-shark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-sheriff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-import",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-wichita",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-bowling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
