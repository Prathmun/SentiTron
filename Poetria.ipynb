{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "leading-anxiety",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json\n",
    "import random\n",
    "import re\n",
    "import pronouncing\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "centered-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This just makes a list of all lines of poetry, sans extra whitespace\n",
    "all_lines =[]\n",
    "for line in gzip.open(\"gutenberg-poetry-v001.ndjson.gz\"):\n",
    "    all_lines.append(json.loads(line.strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "mental-inquiry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds a dictionary that maps words with that rhyming part to the lines of poetry that they're found at the end of.\n",
    "from collections import defaultdict\n",
    "\n",
    "by_rhyming_part = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for line in all_lines:\n",
    "    text = line['s']\n",
    "    if not(32 < len(text) < 48): # only use lines of uniform lengths\n",
    "        continue\n",
    "        # /b indicates word boundaries\n",
    "        # w+ 'word character' alphanumeric I think\n",
    "        # W not word character \n",
    "        \n",
    "    match = re.search(r'(\\b\\w+\\b)\\W*$', text)\n",
    "    \n",
    "    if match:\n",
    "        last_word = match.group()\n",
    "        pronunciations = pronouncing.phones_for_word(last_word)\n",
    "        if len(pronunciations) > 0:\n",
    "               rhyming_part = pronouncing.rhyming_part(pronunciations[0])\n",
    "               # group by rhyming phones (for rhymes) and words (to avoid duplicate words)\n",
    "               by_rhyming_part[rhyming_part][last_word.lower()].append(text)\n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "standing-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_frame = pd.DataFrame(by_rhyming_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "inside-swift",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "justlines = []\n",
    "for each in all_lines:\n",
    "    justlines.append(each['s'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "solid-light",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "no_punct = []\n",
    "for each in justlines:\n",
    "    punctless = each.strip(string.punctuation)\n",
    "    no_punct.append(punctless)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-feeding",
   "metadata": {},
   "source": [
    "### Certain words aren't being caught by my pronunciation checker. Is it 'cause they're old english or something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "english-heading",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#source_word = 'knelling'\n",
    "#print(source_word.isalpha())\n",
    "#phones = pronouncing.phones_for_word(source_word)[0] #\n",
    "#print(phones)\n",
    "#rhyming_part = pronouncing.rhyming_part(phones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-coordination",
   "metadata": {},
   "source": [
    "These words make my prounouncing library dry heave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "systematic-pilot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347149"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words =[]\n",
    "for line in no_punct:\n",
    "    text = line\n",
    "    source_word = text.split(' ')[-1]\n",
    "    try:\n",
    "        pronouncing.phones_for_word(source_word)[0]\n",
    "    except IndexError:\n",
    "        bad_words.append(text.split(' ')[-1])\n",
    "len(bad_words)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "approximate-million",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116925         Pohyola\n",
       "301810        senectus\n",
       "147071           stept\n",
       "150994          to-day\n",
       "110663    master-magic\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_words = pd.Series(bad_words)\n",
    "bad_words.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "together-happening",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_punct_no_repeats = set(no_punct) -set(bad_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rough-services",
   "metadata": {},
   "source": [
    "## Analysis of original corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "swedish-belgium",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Line</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>And sought her 'custom'd couch. Scarce Peleus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>But never leave their firm intent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How gloriously beautiful is earth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And by her girdle hung a purse of leather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As plain as the land of bread</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Line\n",
       "0  And sought her 'custom'd couch. Scarce Peleus ...\n",
       "1                  But never leave their firm intent\n",
       "2                  How gloriously beautiful is earth\n",
       "3          And by her girdle hung a purse of leather\n",
       "4                      As plain as the land of bread"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.DataFrame(no_punct_no_repeats)\n",
    "corpus['Line'] = corpus[0]\n",
    "corpus.drop([0], axis=1, inplace= True)\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "muslim-president",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-confidentiality",
   "metadata": {},
   "source": [
    "# THE MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This whole thing doesn't work super reliably. Some of it has to do with the pronunciation library missing words in my corpus,\n",
    "#some of it has to do with punctuation. Working on it, but it's not super high priority.\n",
    "def limirick_machine(tone_param=True):\n",
    "    #tone_param, sorts sentiment. True = ascending, or sad, false = Descending, or happy\n",
    "    #Finds you lines that don't need to rhyme\n",
    "    def initial_line_finder(list_of_existing):\n",
    "        rand_choice = random.choice(no_punct_no_repeats)\n",
    "        if rand_choice not in list_of_existing:\n",
    "            line = rand_choice\n",
    "            \n",
    "        while line.split(' ')[-1].isalpha() == False:\n",
    "            rand_choice = random.choice(no_punct_no_repeats)\n",
    "            if rand_choice not in list_of_existing:\n",
    "                line = rand_choice\n",
    "        \n",
    "        flag = False\n",
    "        while flag == False:            \n",
    "            try:\n",
    "                \n",
    "                word_to_rhyme = line.split(' ')[-1]\n",
    "                phones = pronouncing.phones_for_word(word_to_rhyme)\n",
    "                phones = phones[0]\n",
    "                flag= True\n",
    "                \n",
    "            except IndexError:  \n",
    "                \n",
    "                rand_choice = random.choice(no_punct_no_repeats)\n",
    "                while line.split(' ')[-1].isalpha() == False:\n",
    "                    rand_choice = random.choice(no_punct_no_repeats)\n",
    "                    if rand_choice not in list_of_existing:\n",
    "                        line = rand_choice\n",
    "                phones = pronouncing.phones_for_word(word_to_rhyme)\n",
    "                phones = phones[0]\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        ###\n",
    "        \n",
    "        rhyming_phones = pronouncing.rhyming_part(phones)\n",
    "        return line, rhyming_phones\n",
    "    \n",
    "    # Finds lines that end with similar rhymes.\n",
    "    def secondary_line_finder(list_of_existing, phones_to_rhyme, cosine_buddy):   \n",
    "        \n",
    "        \n",
    "        rand_choice = ''\n",
    "        ##############################################\n",
    "        \n",
    "        def rhymeme(focus, tone=True):\n",
    "            def sentimenter(line):\n",
    "                sentiment= TextBlob(line).sentiment\n",
    "                subjectivity = sentiment.subjectivity\n",
    "                return (subjectivity)\n",
    "                \n",
    "            line_idx = idx_assign[idx_assign == focus].index[0]\n",
    "            \n",
    "            idx_assign['line'] = idx_assign[0]\n",
    "            idx_assign.drop(inplace=True, axis=1, labels=[0])\n",
    "            \n",
    "            sim_array = cos_sim[line_idx]\n",
    "            \n",
    "            #makes the cosign dataframe\n",
    "            \n",
    "            array_lst = list(enumerate(sim_array))\n",
    "            sort_lst = sorted(array_lst, reverse=True, key = lambda x: x[1])\n",
    "            cosign_df = pd.DataFrame(sort_lst)\n",
    "            #renaming columns\n",
    "            cosign_df['orig_ind'] = cosign_df[0] \n",
    "            cosign_df.drop(inplace=True, axis=1, labels=[0])\n",
    "            cosign_df['cosign_score'] = cosign_df[1]\n",
    "            cosign_df.drop(inplace=True, axis=1, labels=[1])\n",
    "            \n",
    "            #builds a df with both cosign similarity and sentiment in it\n",
    "            #merges cosign df and the df with the rhyming lines in it\n",
    "            co_sentiment_df = idx_assign.merge(cosign_df, left_on='index', right_on='orig_ind')\n",
    "            co_sentiment_df.drop(inplace=True, axis=1, labels=['index', 'orig_ind'])\n",
    "            #applies the sentiment analyzer to the givgen ligns\n",
    "            co_sentiment_df['sentiment'] = co_sentiment_df['line'].apply(sentimenter)\n",
    "            co_sentiment_df.sort_values(['cosign_score'], ascending=False)\n",
    "            \n",
    "            \n",
    "            #Sorts by cosign\n",
    "            sorted_cosign = co_sentiment_df.sort_values(['cosign_score'], ascending=False).head(10)\n",
    "            #Sorts the dataframe by sentiment\n",
    "            sorted_sentiment = sorted_cosign.sort_values(['sentiment'], ascending=False)\n",
    "            sorted_sentiment.drop(axis=0, labels=[0], inplace=tone)\n",
    "\n",
    "            final_phrase = sorted_sentiment['line'].iloc[0]\n",
    "\n",
    "            return final_phrase\n",
    "        ##############################################\n",
    "        \n",
    "        while rand_choice in list_of_existing or rand_choice =='':\n",
    "            key = random.choice(list(by_rhyming_part[phones_to_rhyme].keys()))    \n",
    "            list_of_rhyming_lines = list(by_rhyming_part[phones_to_rhyme][key])\n",
    "\n",
    "            count_vect = CountVectorizer(ngram_range=(1, 2), stop_words='english')\n",
    "\n",
    "            to_vectorize = list_of_rhyming_lines\n",
    "            to_vectorize.append(cosine_buddy)\n",
    "            \n",
    "            \n",
    "            count_matrix = count_vect.fit_transform(to_vectorize)\n",
    "            cos_sim = cosine_similarity(count_matrix)\n",
    "            \n",
    "            rhyming_series = pd.Series(to_vectorize)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            idx_assign = rhyming_series.reset_index() \n",
    "            rand_choice = rhymeme(cosine_buddy, tone_param)\n",
    "            \n",
    "            \n",
    "        return rand_choice\n",
    "            \n",
    "\n",
    "    list_of_lines = []\n",
    "    line1, line1_phones = initial_line_finder(list_of_lines)\n",
    "    list_of_lines.append(line1)\n",
    "        \n",
    "    line2 = secondary_line_finder(list_of_lines, line1_phones, list_of_lines[-1])\n",
    "    list_of_lines.append(line2)\n",
    "    \n",
    "    line3, line3_phones = initial_line_finder(list_of_lines)\n",
    "    list_of_lines.append(line3)\n",
    "    \n",
    "    line4 = secondary_line_finder(list_of_lines, line3_phones,list_of_lines[-1])\n",
    "    list_of_lines.append(line4)\n",
    "    \n",
    "    line5 = secondary_line_finder(list_of_lines, line1_phones,list_of_lines[-1])\n",
    "    \n",
    "\n",
    "    return line1, line2, line3, line4, line5\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "sapphire-audit",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n",
      "  \n",
      "And winds, austere and pure\n",
      "\"He will not. If one evil we endure\n",
      "If care were not the waiter\n",
      "Whilst that vast, breathless amphitheatre\n",
      "And still, behind me--hieroglyph obscure\n"
     ]
    }
   ],
   "source": [
    "line1, line2, line3, line4, line5 = limirick_machine(tone_param=True)\n",
    "print('  ')\n",
    "print('  ')\n",
    "print(line1)\n",
    "print(line2)\n",
    "print(line3)\n",
    "print(line4)\n",
    "print(line5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "faced-warrant",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# #initial set up.\n",
    "# temp_limirick_dict= {'line1':[],'line2':[],'line3':[],'line4':[],'line5':[],}\n",
    "# for i in range(10):\n",
    "#     line1, line2, line3, line4, line5 = limirick_machine()\n",
    "#     temp_limirick_dict['line1'].append(line1)\n",
    "#     temp_limirick_dict['line2'].append(line2)\n",
    "#     temp_limirick_dict['line3'].append(line3)\n",
    "#     temp_limirick_dict['line4'].append(line4)\n",
    "#     temp_limirick_dict['line5'].append(line5)\n",
    "# basic_limirick_df = pd.DataFrame(temp_limirick_dict)\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #increase size\n",
    "# temp_limirick_dict= {'line1':[],'line2':[],'line3':[],'line4':[],'line5':[],}\n",
    "# for i in range(10):\n",
    "#     line1, line2, line3, line4, line5 = limirick_machine()\n",
    "#     temp_limirick_dict['line1'].append(line1)\n",
    "#     temp_limirick_dict['line2'].append(line2)\n",
    "#     temp_limirick_dict['line3'].append(line3)\n",
    "#     temp_limirick_dict['line4'].append(line4)\n",
    "#     temp_limirick_dict['line5'].append(line5)\n",
    "# temp_limirick_df = pd.DataFrame(temp_limirick_dict)\n",
    "# basic_limirick_df = pd.concat([basic_limirick_df, temp_limirick_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-blackberry",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sentimenter(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    subjectivity = sentiment.subjectivity\n",
    "    return (subjectivity)\n",
    "def polarityer(line):\n",
    "    sentiment= TextBlob(line).sentiment\n",
    "    polarity = sentiment.polarity\n",
    "    return (polarity)\n",
    "\n",
    "# for column in basic_limirick_df:\n",
    "#     basic_limirick_df[column + '_sentiment'] = basic_limirick_df[column].apply(sentimenter)\n",
    "#     basic_limirick_df[column + '_polarity'] = basic_limirick_df[column].apply(polarityer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a wordcloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "# Create stopword list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update([\"br\", \"href\"])\n",
    "textt = \" \".join(review for review in basic_limirick_df.line2)\n",
    "wordcloud = WordCloud(stopwords=stopwords).generate(textt)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud11.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-white",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-covering",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-designation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-driver",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-album",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-return",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addressed-shark",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-sheriff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-import",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "postal-typing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-wichita",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-bowling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-medicare",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
